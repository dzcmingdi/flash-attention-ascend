[
  {
    "op": "FlashAttention",
    "name": "flash-attention",
    "input_desc": [
      {
        "format": "ND",
        "shape": [
          16,
          2048,
          192
        ],
        "type": "float16"
      },
      {
        "format": "ND",
        "shape": [
          16,
          192,
          2048
        ],
        "type": "float16"
      },
      {
        "format": "ND",
        "shape": [
          16,
          2048,
          192
        ],
        "type": "float16"
      }
    ],
    "output_desc": [
      {
        "format": "ND",
        "shape": [
          16,
          2048,
          192
        ],
        "type": "float16"
      }
    ]
  }
]
